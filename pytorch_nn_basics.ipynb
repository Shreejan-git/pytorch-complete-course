{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNdEQZZ4Iq7+QBTjDrdQkit",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreejan-git/pytorch-complete-course/blob/main/pytorch_nn_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G_45BzF8pWvh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2x33C50qHKQ",
        "outputId": "5e98c4f5-8af1-4b2d-9f85-fca67a1bdbe5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfkKfwe0qJ5y",
        "outputId": "4da7b384-ec45-48a5-bf03-2a394d2b2971"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 10 05:15:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy data\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "# split data\n",
        "split_size = int(0.8 * len(X))\n",
        "X_train = X[:split_size]\n",
        "y_train = y[:split_size]\n",
        "\n",
        "X_test = X[split_size:]\n",
        "y_test = y[split_size:]\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwwaEtsmUBGO",
        "outputId": "828a3d33-036f-47cb-fca1-928ae90bc535"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 1]) torch.Size([50, 1])\n",
            "torch.Size([40, 1]) torch.Size([40, 1])\n",
            "torch.Size([10, 1]) torch.Size([10, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.device # remember our data is in cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzCPa0X7eVGz",
        "outputId": "42cfc3e6-b2f7-42de-ae9a-2542e9bb24f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "saQBcy5lSFRY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes while creating a custom model:**\n",
        "\n",
        "\n",
        "1.   If we are creating our custom neural network module, it must inherit from nn.Module. https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
        "2.   Always call the __ init __ (constructor) of the parent class using the super().__ init__ (). This is a mandatory step. If we do not call the parents's constructor, we will have problems while training and saving the model. (linked with point 3)\n",
        "3. When we are inheriting from nn.Module, it is mandatory to add forward method. Later while training the model, setting our to model to traning model with model.train(X_train), it will automatically forward_pass using forward method.\n",
        "4. Below, nn.parameter's work is to mark that variable as a learnable parameter. nn.parameter will track it while training.\n"
      ],
      "metadata": {
        "id": "2NEBehP6GspC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below's model architecture is a scratch implementation of a linear model to demonstrate how weight and a bias is initialized and used in a forward method. We have nn.Linear() to do all of these is a single line of code."
      ],
      "metadata": {
        "id": "WZnmRMjLSSLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.rand(1,\n",
        "                               requires_grad=True,\n",
        "                               dtype=torch.float32))\n",
        "    self.bias = nn.Parameter(torch.rand(1,\n",
        "                             requires_grad=True,\n",
        "                             dtype=torch.float32))\n",
        "\n",
        "  def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
        "    return self.weight * X + self.bias\n",
        "# Set the manual seed\n",
        "# torch.manual_seed(42)\n",
        "model = SimpleLinearRegression() # Initializing the model\n",
        "model"
      ],
      "metadata": {
        "id": "Ef-umtmWqpIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680014dd-8721-4a84-9c28-1bb04097985f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleLinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(model.parameters()).device) # checking whether our model is running on a CPU or GPU.\n",
        "# Since it is running on a CPU, let's change it to a GPU\n",
        "model.to(device)\n",
        "print(next(model.parameters()).device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7NUxDCWbk9u",
        "outputId": "e971f253-0b7f-4120-a2ce-2907ee3176c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TCM50I6aZak",
        "outputId": "49a83c35-4be6-4c49-e20e-636bfe6576fa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([0.3248], device='cuda:0')),\n",
              "             ('bias', tensor([0.4651], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLinearRegressionV2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(in_features=1,\n",
        "                                out_features=1)\n",
        "\n",
        "    def forward(self, X_train: torch.Tensor) -> torch.Tensor:\n",
        "        return self.linear(X_train)\n",
        "\n",
        "model_v2 = SimpleLinearRegressionV2()\n",
        "\n",
        "print(model_v2)\n",
        "print(model_v2.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSyME30rXMit",
        "outputId": "c997e22e-03a7-43ff-bf64-c77bd2557f2b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleLinearRegressionV2(\n",
            "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
            ")\n",
            "OrderedDict([('linear.weight', tensor([[-0.1290]])), ('linear.bias', tensor([0.1635]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(model_v2.parameters()).device) # model's paramaters are in CPU\n",
        "model_v2.to(device)\n",
        "print(next(model_v2.parameters()).device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrNFx3OognqQ",
        "outputId": "65cb5ebc-c807-440a-a871-a4484a2a60b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resources for loss and optimization functions**\n",
        "\n",
        "Pytorch Loss function: https://pytorch.org/docs/stable/nn.html#loss-functions , https://neptune.ai/blog/pytorch-loss-functions\n",
        "\n",
        "Pytorch optimization functions: https://pytorch.org/docs/stable/optim.html"
      ],
      "metadata": {
        "id": "D-wtoIGyGDN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the loss function.\n",
        "loss_fun = nn.L1Loss() # L1Loss is MAE loss function.\n",
        "print(loss_fun)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKPB2zTeFnGe",
        "outputId": "a69e90e6-3812-4dd6-98a9-a1e78cabb753"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1Loss()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can define any optimization function. like Adam, SGD, Adagrad.\n",
        "\n",
        "1st parameter of SGD is the model's parameters. We can get this by writing model.parameters().\n",
        "\n",
        "2nd parameter is learning rate (lr). Higher the value, the bigger the steps will be while reducing the gradient to global minima and vice versa."
      ],
      "metadata": {
        "id": "2eIyUX_QiJ3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the optimization function.\n",
        "optimizer = torch.optim.SGD(params=model_v2.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "DgUWd_kCF2Op"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 200"
      ],
      "metadata": {
        "id": "_o0RQkLCi9lM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting the training and evaluation loop**"
      ],
      "metadata": {
        "id": "kGm13Jybi25z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below code explanation:**\n",
        "\n",
        "\n",
        "1.   Line 3: model.train() This line sets the PyTorch model (model) to training mode. In training mode, the model keeps track of the operations and layers that require gradients for backpropagation. This is necessary because some layers, like dropout or batch normalization(if we have one) must be turned on while training and turned off while evaluating.\n",
        "2.   Line 6: y_pred = model(X_train) This line performs a forward pass through the model using the training data X_train. It computes the predicted values (y_pred) based on the current model parameters. This step is a fundamental part of training, as it computes the model's predictions.\n",
        "3. line 12 [IMPORTANT] In PyTorch, when you perform a backward pass (loss.backward()), the gradients of the model's parameters are accumulated in the respective parameter tensors. But, when you're training a neural network with a single loss function and a single backward pass per iteration, you typically want to reset the gradients to zero before each backward pass to avoid accumulating gradients from previous iterations. Without zeroing out gradients, if you run multiple training iterations, the gradients will accumulate over time. This can lead to incorrect gradient updates, making your model's training unstable or divergent. By using optimizer.zero_grad() before each backward pass, you ensure that the gradients are cleared, and only the gradients of the current iteration are used to update the model parameters.\n",
        "4. line 16: loss.backward() This line computes the gradients of the loss with respect to the model's parameters using backpropagation. It calculates how much each parameter needs to be adjusted to minimize the loss. This is a critical step in training neural networks.\n",
        "5. line 19: optimizer.step() After computing the gradients, you update the model's parameters using an optimization algorithm. The optimizer is responsible for adjusting the model's weights based on the computed gradients.\n",
        "6. line26: model.eval() When the evaluation mode is set, few things that happens while training will be haulted like dropout layers might not drop out units during evaluation, and batch normalization uses the population statistics instead of batch statistics.\n",
        "7. line27. torch.inference_mode() is a context manager to disable funcanility such as gradient tracking during the inference/testing time.\n",
        "\n",
        "After that we forward pass with the validation data set and calculate the loss accordingly.\n",
        "\n"
      ],
      "metadata": {
        "id": "mJM-zCi5jZvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "track_epochs = []\n",
        "track_training_loss = []\n",
        "track_validation_loss = []\n",
        "\n",
        "# device agnostic code for data\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Set the model to a traning mode\n",
        "    model_v2.train()\n",
        "\n",
        "    # Forward pass\n",
        "    y_pred = model_v2(X_train)\n",
        "\n",
        "    # Calculate the loss\n",
        "    loss = loss_fun(y_pred, y_train)\n",
        "\n",
        "    # set the gradients to zero\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Perform backpropagation on the loss with respect to the parameters of the model.\n",
        "    # Parameters are those which we set requires_grad = True.\n",
        "    loss.backward()\n",
        "\n",
        "    # step the updated value to the corresponding parameters.\n",
        "    optimizer.step()\n",
        "\n",
        "    # set the model to the evaluation mode.\n",
        "    model_v2.eval()\n",
        "    with torch.inference_mode(): #context manager\n",
        "        val_pred = model_v2(X_test) # validation set\n",
        "        val_loss = loss_fun(val_pred, y_test)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        track_epochs.append(epoch)\n",
        "        track_training_loss.append(loss)\n",
        "        track_validation_loss.append(val_loss)\n",
        "        print(f\"Epoch: {epoch} | Train loss: {loss} | Validation loss: {val_loss}\")"
      ],
      "metadata": {
        "id": "ShDAp3vk8_W_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f152552-bd52-4b50-995d-9d2852112f44"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train loss: 0.4597874581813812 | Validation loss: 0.8608280420303345\n",
            "Epoch: 10 | Train loss: 0.344577431678772 | Validation loss: 0.7261180281639099\n",
            "Epoch: 20 | Train loss: 0.24321754276752472 | Validation loss: 0.600577175617218\n",
            "Epoch: 30 | Train loss: 0.18455743789672852 | Validation loss: 0.5028252005577087\n",
            "Epoch: 40 | Train loss: 0.15319335460662842 | Validation loss: 0.43044620752334595\n",
            "Epoch: 50 | Train loss: 0.1361699253320694 | Validation loss: 0.37697601318359375\n",
            "Epoch: 60 | Train loss: 0.12670813500881195 | Validation loss: 0.33874547481536865\n",
            "Epoch: 70 | Train loss: 0.120749332010746 | Validation loss: 0.31095337867736816\n",
            "Epoch: 80 | Train loss: 0.1162446141242981 | Validation loss: 0.2904769480228424\n",
            "Epoch: 90 | Train loss: 0.1122717410326004 | Validation loss: 0.2733549475669861\n",
            "Epoch: 100 | Train loss: 0.10878171771764755 | Validation loss: 0.2623351514339447\n",
            "Epoch: 110 | Train loss: 0.1052917018532753 | Validation loss: 0.2513153851032257\n",
            "Epoch: 120 | Train loss: 0.10180169343948364 | Validation loss: 0.24029560387134552\n",
            "Epoch: 130 | Train loss: 0.09831168502569199 | Validation loss: 0.22927582263946533\n",
            "Epoch: 140 | Train loss: 0.09487288445234299 | Validation loss: 0.2210034877061844\n",
            "Epoch: 150 | Train loss: 0.09143408387899399 | Validation loss: 0.2127309888601303\n",
            "Epoch: 160 | Train loss: 0.0880042240023613 | Validation loss: 0.20514535903930664\n",
            "Epoch: 170 | Train loss: 0.08456927537918091 | Validation loss: 0.19687281548976898\n",
            "Epoch: 180 | Train loss: 0.0811307355761528 | Validation loss: 0.18928715586662292\n",
            "Epoch: 190 | Train loss: 0.07770229130983353 | Validation loss: 0.18101462721824646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_v2.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvNUJlZwfQhI",
        "outputId": "7c48684f-3765-4e30-903f-cd057d29b84d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear.weight', tensor([[0.3305]], device='cuda:0')),\n",
              "             ('linear.bias', tensor([0.4550], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning curve\n",
        "plt.plot(track_epochs, np.array(torch.tensor(track_training_loss).numpy()), label=\"Training loss\")\n",
        "plt.plot(track_epochs, track_validation_loss, label=\"Validation loss\")\n",
        "plt.title('Learning curve')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "XUI_OG1w9AyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KRxrr3VB9BT3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7okZTnjs9BpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "grvpgRv09B-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MvZikrqeqosG"
      }
    }
  ]
}